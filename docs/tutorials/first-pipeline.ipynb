{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A first pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('example.txt', 'r') as f:\n",
    "    text = f.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Spacy pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Importating Spacy\n",
    "import spacy"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Loading EDS-NLP pipelines\n",
    "import edsnlp.components"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creates the Spacy instance\n",
    "nlp = spacy.blank('fr')\n",
    "\n",
    "# Normalisation of accents, case and other special characters\n",
    "nlp.add_pipe('normalizer')\n",
    "# Detecting end of lines\n",
    "nlp.add_pipe('sentences')\n",
    "\n",
    "# Extraction of named entities\n",
    "nlp.add_pipe(\n",
    "    'matcher',\n",
    "    config=dict(\n",
    "        terms=dict(respiratoire=[\n",
    "            'difficultes respiratoires',\n",
    "            'asthmatique',\n",
    "            'toux',\n",
    "        ]),\n",
    "        regex=dict(\n",
    "            covid=r'(?i)(?:infection\\sau\\s)?(covid[\\s\\-]?19|corona[\\s\\-]?virus)',\n",
    "            traitement=r'(?i)traitements?|medicaments?'),\n",
    "        attr='NORM',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Qualification of the entities\n",
    "nlp.add_pipe('negation')\n",
    "nlp.add_pipe('hypothesis')\n",
    "nlp.add_pipe('family')\n",
    "nlp.add_pipe('rspeech')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "doc = nlp(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "doc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Processing by EDS-NLP (and Spacy in general) are all non-destructive :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Non-destruction\n",
    "doc.text == text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For tasks such as normalization, EDS-NLP adds attributes to tokens, without information loss:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normalisation\n",
    "print(f\"{'text':<15}\", 'normalisation')\n",
    "print(f\"{'----':<15}\", '-------------')\n",
    "for token in doc[3:15]:\n",
    "    print(f\"{token.text:<15}\", f\"{token.norm_}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipeline we defined above extracted named entities using the `matcher` component."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we inherit from Spacy, we can use their utilities :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from spacy import displacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "displacy.render(\n",
    "    doc,\n",
    "    style='ent',\n",
    "    options={'colors': dict(respiratoire='green', covid='orange')},\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's focus on the fist entity :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "entity = doc.ents[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "entity"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "entity._.negated"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can reformat the entities to an OMOP-like format:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame.from_records([\n",
    "    dict(\n",
    "        label=ent.label_,\n",
    "        start_char=ent.start_char,\n",
    "        end_char=ent.end_char,\n",
    "        lexical_variant=ent.text,\n",
    "        negation=ent._.negated,\n",
    "        family=ent._.family,\n",
    "        hypothesis=ent._.hypothesis,\n",
    "        rspeech=ent._.reported_speech,\n",
    "    )\n",
    "    for ent in doc.ents\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
